{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zbq-XQZLe2bL"
      },
      "source": [
        "# Image Colorization with U-Net and GAN Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq5QpROue2bS"
      },
      "source": [
        "**If you have already read the explanations, you can directly go to the code starting with heading: _1 - Implementing the paper - Our Baseline_**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxyg_agWe2bU"
      },
      "source": [
        "![title image](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/main.png?raw=1)\n",
        "\n",
        "One of the most exciting applications of deep learning is colorizing black and white images.  This task needed a lot of human input and hardcoding several years ago but now the whole process can be done end-to-end with the power of AI and deep learning. You might think that you need huge amount of data or long training times to train your model from scratch for this task but in the last few weeks I worked on this and tried many different model architectures, loss functions, training strategies, etc. and finally developed an efficient strategy to train such a model, using the latest advances in deep learning, on a rather small dataset and with really short training times. In this article, I'm going to explain what I did to make this happen, including the code!, and the strategies that helped and also those that were not useful. Before that, I will explain the colorization problem and a give you a short review of what has been done in recent years. I'll assume you have basic knowledge about deep learning, GANs, and PyTorch library for the rest of the article. Let's begin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHrebRM1e2bW"
      },
      "source": [
        "## Introduction to colorization problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O87kEvF-e2bY"
      },
      "source": [
        "Here I'm going to give you some basic knowledge that you may need to understand what the models do in the following codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtMk0ZK2e2bZ"
      },
      "source": [
        "### RGB vs L\\*a\\*b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM2aLe6Ze2ba"
      },
      "source": [
        "As you might know, when we load an image, we get a rank-3 (height, width, color) array with the last axis containing the color data for our image. These data represent color in RGB color space and there are 3 numbers for each pixel indicating how much Red, Green, and Blue the pixel is. In the following image you can see that in the left part of the \"main image\" (the leftmost image) we have blue color so in the blue channel of the image, that part has higher values and has turned dark.\n",
        "\n",
        "![rgb image](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/rgb.jpg?raw=1)\n",
        "\n",
        "In L\\*a\\*b color space, we have again three numbers for each pixel but these numbers have different meanings. The first number (channel), L, encodes the Lightness of each pixel and when we visualize this channel (the second image in the row below) it appears as a black and white image. The \\*a and \\*b channels encode how much green-red and yellow-blue each pixel is, respectively. In the following image you can see each channel of L\\*a\\*b color space separately.\n",
        "\n",
        "![lab image](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/lab.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfuTZ3ue2bd"
      },
      "source": [
        "In all papers I studied and all codes I checked out on colorization on GitHub, people use L\\*a\\*b color space instead of RGB to train the models. There are a couple of reasons for this choice but I'll give you an intuition of why we make this choice. To train a model for colorization, we should give it a grayscale image and hope that it will make it colorful. When using L\\*a\\*b, we can give the L channel to the model (which is the grayscale image) and want it to predict the other two channels (\\*a, \\*b) and after its prediction, we concatenate all the channels and we get our colorful image. But if you use RGB, you have to first convert your image to grayscale, feed the grayscale image to the model and hope it will predict 3 numbers for you which is a way more difficult and unstable task due to the many more possible combinations of 3 numbers compared to two numbers. If we assume we have 256 choices (in a 8-bit unsigned integer image this is the real number of choices) for each number, predicting the three numbers for each of the pixels is choosing between 256³ combinations which is more than 16 million choices, but when predicting two numbers we have about 65000 choices (actually, we are not going to wildly choose these numbers like a classification task and I just wrote these numbers to give you an intuition)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM3b6KJje2be"
      },
      "source": [
        "## How to solve the problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeNB2JtAe2bf"
      },
      "source": [
        "During the last few years, many different solutions have been proposed to colorize images by using deep learning. [_**Colorful Image Colorization**_](https://arxiv.org/abs/1603.08511) paper approached the problem as a classification task and they also considered the uncertainty of this problem (e.x. a car in the image can take on many different and valid colors and we cannot be sure about any color for it); however, another paper approached the problem as a regression task (with some more tweaks!). There are pros and cons to each approach but in this article, we are going to use a different strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igQLv95Ue2bf"
      },
      "source": [
        "### The strategy we are going to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3KpzyyEe2bg"
      },
      "source": [
        "[_**Image-to-Image Translation with Conditional Adversarial Networks**_](https://arxiv.org/abs/1611.07004) paper, which you may know by the name pix2pix, proposed a general solution to many image-to-image tasks in deep learning which one of those was colorization. In this approach two losses are used: L1 loss, which makes it a regression task, and an adversarial (GAN) loss, which helps to solve the problem in an unsupervised manner (by assigning the outputs a number indicating how \"real\" they look!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXITidPhe2bg"
      },
      "source": [
        "In this tutorial, I will first implement what the authors did in the paper and then I will introduce a whole new generator model and some tweaks in the strategy of training which significantly helps reduce the size of needed dataset while getting amazing results. So stay tuned :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8UY7IfSe2bh"
      },
      "source": [
        "### A deeper dive into GAN world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kau1RxXHe2bh"
      },
      "source": [
        "As mentioned earlier, we are going to build a GAN (a conditional GAN to be specific) and use an extra loss function, L1 loss. Let's start with the GAN.\n",
        "\n",
        "As you might know, in a GAN we have a generator and a discriminator model which learn to solve a problem together. In our setting, the generator model takes a grayscale image (1-channel image) and produces a 2-channel image, a channel for \\*a and another for \\*b. The discriminator, takes these two produced channels and concatenates them with the input grayscale image and decides whether this new 3-channel image is fake or real. Of course the discriminator also needs to see some real images (3-channel images again in Lab color space) that are not produced by the generator and should learn that they are real.\n",
        "\n",
        "So what about the \"condition\" we mentioned? Well, that grayscale image which both the generator and discriminator see is the condition that we provide to both models in our GAN and expect that the they take this condition into consideration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bh0XJaGe2bh"
      },
      "source": [
        "Let's take a look at the math. Consider _**x**_ as the grayscale image, _**z**_ as the input noise for the generator, and _**y**_ as the 2-channel output we want from the generator (it can also represent the 2 color channels of a real image). Also, _**G**_ is the generator model and _**D**_ is the discriminator. Then the loss for our conditional GAN will be:\n",
        "\n",
        "![GAN Loss](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/GAN_loss.jpg?raw=1)\n",
        "\n",
        "Notice that _**x**_ is given to both models which is the condition we introduce two both players of this game. Actually, we are not going to feed a \"n\" dimensional vector of random noise to the generator as you might expect but the noise is introduced in the form of dropout layers (there is something cool about it which you will read in the last section of the article) in the generator architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoH0YRY-e2bi"
      },
      "source": [
        "### Loss function we optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQHztdCMe2bi"
      },
      "source": [
        "The earlier loss function helps to produce good-looking colorful images that seem real, but to further help the models and introduce some supervision in our task, we combine this loss function with L1 Loss (you might know L1 loss as mean absolute error) of the predicted colors compared with the actual colors:\n",
        "\n",
        "![L1 loss](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/l1_loss.jpg?raw=1)\n",
        "\n",
        "If we use L1 loss alone, the model still learns to colorize the images but it will be conservative and most of the time uses colors like \"gray\" or \"brown\" because when it doubts which color is the best, it takes the average and uses these colors to reduce the L1 loss as much as possible (it is similar to the blurring effect of L1 or L2 loss in super resolution task). Also, the L1 Loss is preferred over L2 loss (or mean squared error) because it reduces that effect of producing gray-ish images. So, our combined loss function will be:\n",
        "\n",
        "![loss](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/loss.jpg?raw=1)\n",
        "\n",
        "where _**λ**_ is a coefficient to balance the contribution of the two losses to the final loss (of course the discriminator loss does not involve the L1 loss)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNy7QzARe2bj"
      },
      "source": [
        "Okay. I think it's enough for theory! Let's get our hands dirty with the code! In the following section, **I first introduce the code to implement the paper** and in the section after that, **I will introduce a better strategy to get really amazing results in one or two hours of training and without needing huge amount of data!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfnKhQj6e2bj"
      },
      "source": [
        "## 1 - Implementing the paper - Our Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4GbcR_Oe2bj"
      },
      "source": [
        "### 1.1- Loading Image Paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ww6eVBle2bk"
      },
      "source": [
        "The paper uses the whole ImageNet dataset (with 1.3 million images!) but here I'm using only 8,000 images from COCO dataset for training which I had available on my device. So our training set size is 0.6% of what was used in the paper!\n",
        "You can use almost any dataset for this task as far as it contains many different scenes and locations which you hope it will learn to colorize. You can use ImageNet for example but you will only need 8000 of its images for this project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JG_Ox_K-e2bk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "use_colab = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twtG8C9ae2bl"
      },
      "source": [
        "### 1.1.x Preparing Colab for running the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzdNLdb2e2bm"
      },
      "source": [
        "If you are opening this on **Google Colab** you can uncomment and run the following to install fastai. Almost all of the code in the tutorial is with **pure PyTorch**. We need fastai here only to download part of COCO dataset and in one other step in the second section of the tutorial.\n",
        "\n",
        "Also make sure to set your runtime to **GPU** to be able to train the models much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xDDDBoTqe2bm"
      },
      "outputs": [],
      "source": [
        "#!pip install fastai==2.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA7yIac-e2bm"
      },
      "source": [
        "The following will download about 20,000 images from COCO dataset. Notice that **we are going to use only 8000 of them** for training. Also you can use any other dataset like ImageNet as long as it contains various scenes and locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0PJqTX1We2bm"
      },
      "outputs": [],
      "source": [
        "# from fastai.data.external import untar_data, URLs\n",
        "# coco_path = untar_data(URLs.COCO_SAMPLE)\n",
        "# coco_path = str(coco_path) + \"/train_sample\"\n",
        "# use_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bmP2d7D7e2bn",
        "outputId": "6ab75aa7-78a5-4898-e521-8a6122bb283f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80 20\n"
          ]
        }
      ],
      "source": [
        "if use_colab == True:\n",
        "    path = coco_path\n",
        "else:\n",
        "    path = '/content/drive/MyDrive/hi/datasetforpix2pixfinal'\n",
        "\n",
        "paths = glob.glob(path + \"/*.png\") # Grabbing all the image file names\n",
        "np.random.seed(123)\n",
        "paths_subset = np.random.choice(paths, 100, replace=False) # choosing 1000 images randomly\n",
        "rand_idxs = np.random.permutation(100)\n",
        "train_idxs = rand_idxs[:80] # choosing the first 8000 as training set\n",
        "val_idxs = rand_idxs[80:] # choosing last 2000 as validation set\n",
        "train_paths = paths_subset[train_idxs]\n",
        "val_paths = paths_subset[val_idxs]\n",
        "print(len(train_paths), len(val_paths))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(path)"
      ],
      "metadata": {
        "id": "MFR8Ws97xmw9",
        "outputId": "dac178ce-74bf-486d-9d73-3839392e6735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hi/datasetforpix2pixfinal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Z3iTM2Uue2bn",
        "outputId": "4b32eb97-a6cd-41c8-e587-87cd3d582516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "_, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "for ax, img_path in zip(axes.flatten(), train_paths):\n",
        "    ax.imshow(Image.open(img_path))\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5GzE2Y3ev8Rr",
        "outputId": "afb14ab3-330d-400b-8d63-4a8620764764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qwfihf-e2bo"
      },
      "source": [
        "Although we are using the same dataset and number of training samples, the exact 8000 images that you train your model on may vary (although we are seeding!) because the dataset here has only 20000 images with different ordering while I sampled 10000 images from the complete dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LptX1meve2bo"
      },
      "source": [
        "### 1.2- Making Datasets and DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ62eOyee2bo"
      },
      "source": [
        "I hope the code is self-explanatory. I'm resizing the images and flipping horizontally (flipping only if it is training set) and then I read an RGB image, convert it to Lab color space and separate the first (grayscale) channel and the color channels as my inputs and targets for the models  respectively. Then I'm making the data loaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "88WW7OZQe2bo"
      },
      "outputs": [],
      "source": [
        "SIZE = 256\n",
        "class ColorizationDataset(Dataset):\n",
        "    def __init__(self, paths, split='train'):\n",
        "        if split == 'train':\n",
        "            self.transforms = transforms.Compose([\n",
        "                transforms.Resize((SIZE, SIZE),  Image.BICUBIC),\n",
        "                transforms.RandomHorizontalFlip(), # A little data augmentation!\n",
        "            ])\n",
        "        elif split == 'val':\n",
        "            self.transforms = transforms.Resize((SIZE, SIZE),  Image.BICUBIC)\n",
        "\n",
        "        self.split = split\n",
        "        self.size = SIZE\n",
        "        self.paths = paths\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx]).convert(\"RGB\")\n",
        "        img = self.transforms(img)\n",
        "        img = np.array(img)\n",
        "        img_lab = rgb2lab(img).astype(\"float32\") # Converting RGB to L*a*b\n",
        "        img_lab = transforms.ToTensor()(img_lab)\n",
        "        L = img_lab[[0], ...] / 50. - 1. # Between -1 and 1\n",
        "        ab = img_lab[[1, 2], ...] / 110. # Between -1 and 1\n",
        "\n",
        "        return {'L': L, 'ab': ab}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "def make_dataloaders(batch_size=16, n_workers=4, pin_memory=True, **kwargs): # A handy function to make our dataloaders\n",
        "    dataset = ColorizationDataset(**kwargs)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=n_workers,\n",
        "                            pin_memory=pin_memory)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wCF5BGeEe2bp",
        "outputId": "2f44effc-f830-4dab-b7bd-e76d861ec6ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 256, 256]) torch.Size([16, 2, 256, 256])\n",
            "5 2\n"
          ]
        }
      ],
      "source": [
        "train_dl = make_dataloaders(paths=train_paths, split='train')\n",
        "val_dl = make_dataloaders(paths=val_paths, split='val')\n",
        "\n",
        "data = next(iter(train_dl))\n",
        "Ls, abs_ = data['L'], data['ab']\n",
        "print(Ls.shape, abs_.shape)\n",
        "print(len(train_dl), len(val_dl))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVlW8jPDe2bp"
      },
      "source": [
        "### 1.3- Generator proposed by the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rA6a7vFe2bq"
      },
      "source": [
        "This one is a little complicated and needs explanation. This code implements a U-Net to be used as the generator of our GAN. The details of the code are out of the scope of this article but the important thing to understand is that it makes the U-Net from the middle part of it (down in the U shape) and adds down-sampling and up-sampling modules to the left and right of that middle module (respectively) at every iteration until it reaches the input module and output module. Look at the following image that I made from one of the images in the article to give you a better sense of what is happening in the code:\n",
        "\n",
        "![unet](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/unet.png?raw=1)\n",
        "\n",
        "The blue rectangles show the order in which the related modules are built with the code. The U-Net we will build has more layers than what is depicted in this image but it suffices to give you the idea. Also notice in the code that we are going 8 layers down, so if we start with a 256 by 256 image, in the middle of the U-Net we will get a 1 by 1 (256 / 2⁸) image and then it gets up-sampled to produce a  256 by 256 image (with two channels). This code snippet is really exciting and I highly recommend to play with it to fully grasp what every line of it is doing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uuAiwhhke2bq"
      },
      "outputs": [],
      "source": [
        "class UnetBlock(nn.Module):\n",
        "    def __init__(self, nf, ni, submodule=None, input_c=None, dropout=False,\n",
        "                 innermost=False, outermost=False):\n",
        "        super().__init__()\n",
        "        self.outermost = outermost\n",
        "        if input_c is None: input_c = nf\n",
        "        downconv = nn.Conv2d(input_c, ni, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=False)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = nn.BatchNorm2d(ni)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = nn.BatchNorm2d(nf)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(ni, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(ni * 2, nf, kernel_size=4,\n",
        "                                        stride=2, padding=1, bias=False)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            if dropout: up += [nn.Dropout(0.5)]\n",
        "            model = down + [submodule] + up\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, input_c=1, output_c=2, n_down=8, num_filters=64):\n",
        "        super().__init__()\n",
        "        unet_block = UnetBlock(num_filters * 8, num_filters * 8, innermost=True)\n",
        "        for _ in range(n_down - 5):\n",
        "            unet_block = UnetBlock(num_filters * 8, num_filters * 8, submodule=unet_block, dropout=True)\n",
        "        out_filters = num_filters * 8\n",
        "        for _ in range(3):\n",
        "            unet_block = UnetBlock(out_filters // 2, out_filters, submodule=unet_block)\n",
        "            out_filters //= 2\n",
        "        self.model = UnetBlock(output_c, out_filters, input_c=input_c, submodule=unet_block, outermost=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh16rc24e2bq"
      },
      "source": [
        "### 1.4- Discriminator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N183na1ye2b3"
      },
      "source": [
        "The architecture of our discriminator is rather straight forward. This code implements a model by stacking blocks of Conv-BatchNorm-LeackyReLU to decide whether the input image is fake or real. Notice that the first and last blocks do not use normalization and the last block has no activation function (it is embedded in the loss function we will use)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NPYUB-75e2b3"
      },
      "outputs": [],
      "source": [
        "class PatchDiscriminator(nn.Module):\n",
        "    def __init__(self, input_c, num_filters=64, n_down=3):\n",
        "        super().__init__()\n",
        "        model = [self.get_layers(input_c, num_filters, norm=False)]\n",
        "        model += [self.get_layers(num_filters * 2 ** i, num_filters * 2 ** (i + 1), s=1 if i == (n_down-1) else 2)\n",
        "                          for i in range(n_down)] # the 'if' statement is taking care of not using\n",
        "                                                  # stride of 2 for the last block in this loop\n",
        "        model += [self.get_layers(num_filters * 2 ** n_down, 1, s=1, norm=False, act=False)] # Make sure to not use normalization or\n",
        "                                                                                             # activation for the last layer of the model\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def get_layers(self, ni, nf, k=4, s=2, p=1, norm=True, act=True): # when needing to make some repeatitive blocks of layers,\n",
        "        layers = [nn.Conv2d(ni, nf, k, s, p, bias=not norm)]          # it's always helpful to make a separate method for that purpose\n",
        "        if norm: layers += [nn.BatchNorm2d(nf)]\n",
        "        if act: layers += [nn.LeakyReLU(0.2, True)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7L9BJL-e2b4"
      },
      "source": [
        "Let's take a look at its blocks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vqnJutf_e2b5",
        "outputId": "7239922c-63d7-43ab-ab93-dde33465733e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PatchDiscriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "PatchDiscriminator(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPUNoujje2b6"
      },
      "source": [
        "And its output shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "b6IFpg6Ke2b6",
        "outputId": "8f39b52a-4c8f-49b1-abca-8b3198b27a52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1, 30, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "discriminator = PatchDiscriminator(3)\n",
        "dummy_input = torch.randn(16, 3, 256, 256) # batch_size, channels, size, size\n",
        "out = discriminator(dummy_input)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBBmX9Sxe2b7"
      },
      "source": [
        "We are using a \"Patch\" Discriminator here. Okay, what is it?! In a vanilla discriminator, the model outputs one number (a scaler) which represents how much the model thinks the input (which is the whole image) is real (or fake). In a patch discriminator, the model outputs one number for every patch of say 70 by 70 pixels of the input image and for each of them decides whether it is fake or not separately. Using such a model for the task of colorization seems reasonable to me because the local changes that the model needs to make are really important and maybe deciding on the whole image as in vanilla discriminator cannot take care of the subtleties of this task. Here, the model's output shape is 30 by 30 but it does not mean that our patches are 30 by 30. The actual patch size is obtained when you compute the receptive field of each of these 900 (30 multiplied by 30) output numbers which in our case will be 70 by 70."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvWrThRpe2b7"
      },
      "source": [
        "### 1.5- GAN Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCA80Zlre2b7"
      },
      "source": [
        "This is a handy class we can use to calculate the GAN loss of our final model. In the __init__ we decide which kind of loss we're going to use (which will be \"vanilla\" in our project) and register some constant tensors as the \"real\" and \"fake\" labels. Then when we call this module, it makes an appropriate tensor full of zeros or ones (according to what we need at the stage) and computes the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2JtJb1zie2b8"
      },
      "outputs": [],
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, gan_mode='vanilla', real_label=1.0, fake_label=0.0):\n",
        "        super().__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(fake_label))\n",
        "        if gan_mode == 'vanilla':\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "        elif gan_mode == 'lsgan':\n",
        "            self.loss = nn.MSELoss()\n",
        "\n",
        "    def get_labels(self, preds, target_is_real):\n",
        "        if target_is_real:\n",
        "            labels = self.real_label\n",
        "        else:\n",
        "            labels = self.fake_label\n",
        "        return labels.expand_as(preds)\n",
        "\n",
        "    def __call__(self, preds, target_is_real):\n",
        "        labels = self.get_labels(preds, target_is_real)\n",
        "        loss = self.loss(preds, labels)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQfoiwaOe2b8"
      },
      "source": [
        "### 1.x Model Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Suxzuhsge2b8"
      },
      "source": [
        "In the TowardsDataScince article, I didn't explain this function. Here is our logic to initialize our models. We are going to initialize the weights of our model with a mean of 0.0 and standard deviation of 0.02 which are the proposed hyperparameters in the article:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "eudE4irze2b8"
      },
      "outputs": [],
      "source": [
        "def init_weights(net, init='norm', gain=0.02):\n",
        "\n",
        "    def init_func(m):\n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
        "            if init == 'norm':\n",
        "                nn.init.normal_(m.weight.data, mean=0.0, std=gain)\n",
        "            elif init == 'xavier':\n",
        "                nn.init.xavier_normal_(m.weight.data, gain=gain)\n",
        "            elif init == 'kaiming':\n",
        "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                nn.init.constant_(m.bias.data, 0.0)\n",
        "        elif 'BatchNorm2d' in classname:\n",
        "            nn.init.normal_(m.weight.data, 1., gain)\n",
        "            nn.init.constant_(m.bias.data, 0.)\n",
        "\n",
        "    net.apply(init_func)\n",
        "    print(f\"model initialized with {init} initialization\")\n",
        "    return net\n",
        "\n",
        "def init_model(model, device):\n",
        "    model = model.to(device)\n",
        "    model = init_weights(model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePpva-Fse2b9"
      },
      "source": [
        "### 1.6- Putting everything together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPt1ThYDe2b9"
      },
      "source": [
        "This class brings together all the previous parts and implements a few methods to take care of training our complete model. Let's investigate it.\n",
        "\n",
        "In the __init__ we define our generator and discriminator using the previous functions and classes we defined and we also initialize them with init_model function which I didn't explain here but you can refer to my GitHub repository to see how it works. Then we define our two loss functions and the optimizers of the generator and discriminator.\n",
        "\n",
        "The whole work is being done in optimize method of this class. First and only once per iteration (batch of training set) we call the module's forward method and store the outputs in fake_color variable of the class.\n",
        "\n",
        "Then, we first train the discriminator by using backward_D method in which we feed the fake images produced by generator to the discriminator (make sure to detach them from the generator's graph so that they act as a constant to the discriminator, like normal images) and label them as fake. Then we feed a batch of real images from training set to the discriminator and label them as real. We add up the two losses for fake and real and take the average and then call the backward on the final loss.\n",
        "Now, we can train the generator. In backward_G method we feed the discriminator the fake image and try to fool it by assigning real labels to them and calculating the adversarial loss. As I mentioned earlier, we use L1 loss as well and compute the distance between the predicted two channels and the target two channels and multiply this loss by a coefficient (which is 100 in our case) to balance the two losses and then add this loss to the adversarial loss. Then we call the backward method of the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "mTrYU7a6e2b9"
      },
      "outputs": [],
      "source": [
        "class MainModel(nn.Module):\n",
        "    def __init__(self, net_G=None, lr_G=2e-4, lr_D=2e-4,\n",
        "                 beta1=0.5, beta2=0.999, lambda_L1=100.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.lambda_L1 = lambda_L1\n",
        "\n",
        "        if net_G is None:\n",
        "            self.net_G = init_model(Unet(input_c=1, output_c=2, n_down=8, num_filters=64), self.device)\n",
        "        else:\n",
        "            self.net_G = net_G.to(self.device)\n",
        "        self.net_D = init_model(PatchDiscriminator(input_c=3, n_down=3, num_filters=64), self.device)\n",
        "        self.GANcriterion = GANLoss(gan_mode='vanilla').to(self.device)\n",
        "        self.L1criterion = nn.L1Loss()\n",
        "        self.opt_G = optim.Adam(self.net_G.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
        "        self.opt_D = optim.Adam(self.net_D.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
        "\n",
        "    def set_requires_grad(self, model, requires_grad=True):\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = requires_grad\n",
        "\n",
        "    def setup_input(self, data):\n",
        "        self.L = data['L'].to(self.device)\n",
        "        self.ab = data['ab'].to(self.device)\n",
        "\n",
        "    def forward(self):\n",
        "        self.fake_color = self.net_G(self.L)\n",
        "\n",
        "    def backward_D(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image.detach())\n",
        "        self.loss_D_fake = self.GANcriterion(fake_preds, False)\n",
        "        real_image = torch.cat([self.L, self.ab], dim=1)\n",
        "        real_preds = self.net_D(real_image)\n",
        "        self.loss_D_real = self.GANcriterion(real_preds, True)\n",
        "        self.loss_D = (self.loss_D_fake + self.loss_D_real) * 0.5\n",
        "        self.loss_D.backward()\n",
        "\n",
        "    def backward_G(self):\n",
        "        fake_image = torch.cat([self.L, self.fake_color], dim=1)\n",
        "        fake_preds = self.net_D(fake_image)\n",
        "        self.loss_G_GAN = self.GANcriterion(fake_preds, True)\n",
        "        self.loss_G_L1 = self.L1criterion(self.fake_color, self.ab) * self.lambda_L1\n",
        "        self.loss_G = self.loss_G_GAN + self.loss_G_L1\n",
        "        self.loss_G.backward()\n",
        "\n",
        "    def optimize(self):\n",
        "        self.forward()\n",
        "        self.net_D.train()\n",
        "        self.set_requires_grad(self.net_D, True)\n",
        "        self.opt_D.zero_grad()\n",
        "        self.backward_D()\n",
        "        self.opt_D.step()\n",
        "\n",
        "        self.net_G.train()\n",
        "        self.set_requires_grad(self.net_D, False)\n",
        "        self.opt_G.zero_grad()\n",
        "        self.backward_G()\n",
        "        self.opt_G.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVABEjSae2b9"
      },
      "source": [
        "### 1.xx Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YOuOLTte2b-"
      },
      "source": [
        "These functions were nor included in the explanations of the TDS article. These are just some utility functions to log the losses of our network and also visualize the results during training. So here you can check them out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0Q2ZUpYge2b-"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.count, self.avg, self.sum = [0.] * 3\n",
        "\n",
        "    def update(self, val, count=1):\n",
        "        self.count += count\n",
        "        self.sum += count * val\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def create_loss_meters():\n",
        "    loss_D_fake = AverageMeter()\n",
        "    loss_D_real = AverageMeter()\n",
        "    loss_D = AverageMeter()\n",
        "    loss_G_GAN = AverageMeter()\n",
        "    loss_G_L1 = AverageMeter()\n",
        "    loss_G = AverageMeter()\n",
        "\n",
        "    return {'loss_D_fake': loss_D_fake,\n",
        "            'loss_D_real': loss_D_real,\n",
        "            'loss_D': loss_D,\n",
        "            'loss_G_GAN': loss_G_GAN,\n",
        "            'loss_G_L1': loss_G_L1,\n",
        "            'loss_G': loss_G}\n",
        "\n",
        "def update_losses(model, loss_meter_dict, count):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        loss = getattr(model, loss_name)\n",
        "        loss_meter.update(loss.item(), count=count)\n",
        "\n",
        "def lab_to_rgb(L, ab):\n",
        "    \"\"\"\n",
        "    Takes a batch of images\n",
        "    \"\"\"\n",
        "\n",
        "    L = (L + 1.) * 50.\n",
        "    ab = ab * 110.\n",
        "    Lab = torch.cat([L, ab], dim=1).permute(0, 2, 3, 1).cpu().numpy()\n",
        "    rgb_imgs = []\n",
        "    for img in Lab:\n",
        "        img_rgb = lab2rgb(img)\n",
        "        rgb_imgs.append(img_rgb)\n",
        "    return np.stack(rgb_imgs, axis=0)\n",
        "\n",
        "def visualize(model, data, save=True):\n",
        "    model.net_G.eval()\n",
        "    with torch.no_grad():\n",
        "        model.setup_input(data)\n",
        "        model.forward()\n",
        "    model.net_G.train()\n",
        "    fake_color = model.fake_color.detach()\n",
        "    real_color = model.ab\n",
        "    L = model.L\n",
        "    fake_imgs = lab_to_rgb(L, fake_color)\n",
        "    real_imgs = lab_to_rgb(L, real_color)\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(5):\n",
        "        ax = plt.subplot(3, 5, i + 1)\n",
        "        ax.imshow(L[i][0].cpu(), cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 5)\n",
        "        ax.imshow(fake_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "        ax = plt.subplot(3, 5, i + 1 + 10)\n",
        "        ax.imshow(real_imgs[i])\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()\n",
        "    if save:\n",
        "        fig.savefig(f\"colorization_{time.time()}.png\")\n",
        "\n",
        "def log_results(loss_meter_dict):\n",
        "    for loss_name, loss_meter in loss_meter_dict.items():\n",
        "        print(f\"{loss_name}: {loss_meter.avg:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMVUjHDje2b_"
      },
      "source": [
        "### 1.7- Training function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4rn6IFCe2b_"
      },
      "source": [
        "I hope this code is self-explanatory. Every epoch takes about 4 minutes on not a powerful GPU as Nvidia P5000. So if you are using 1080Ti or higher, it will be much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "y9cAtbMte2b_",
        "outputId": "4f94d1a8-5951-426b-890e-4ee528006c99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548,
          "referenced_widgets": [
            "a1cbd8a15c8d46b19592d304257b51fd",
            "1226adf58bc648a092a2d738aae6bd54",
            "d78a8ac934da426287a78f74bf62a356",
            "7b6123098bb447c689a1f8ba9c9c59c9",
            "7c268f2e49ac4cbe9b303cdbaab10b65",
            "99a235ff24cf45f598fa848e27a752c1",
            "437a0b8864f348cb878e4057134dfe2f",
            "ca688562fc134ac8820addb3992c6275",
            "9e735fb91fff46e7bad1cdfbc3c04250",
            "2340cb03c4ed4062b0ffbe79467d90d3",
            "e1bfdd07017b4cec9f6271fc52ebae38",
            "fecffb9bd21a466e9d3adb78f4fa8cdd",
            "51de08c352d24568975f4eb088a5e377",
            "1d07e546e5f94b36a1da5aeaae4e5fef",
            "5f6b42ef5e474117b1c66e21d03bc1e0",
            "19bd16d82c8f4930a2fbd5e44599f7fb",
            "b62e272bb4f44ed5adc93a3896da823e",
            "88c5332ace35437a946074f9fa867652",
            "3cf9bcaa80244c02825aea36ca56902e",
            "bad6f640cbaf46bd80a152d787fc2adb",
            "d33a494d1dc04369ab4ed235049d13ea",
            "e1b666e08e824f79b4c21336fc0bbbe5",
            "43e0b10e024b443da1c37f190fc07bb8",
            "c4947df8fd7b44d186003b8dd426f2b9",
            "f2a224e39c21442fa619191e27daa45b",
            "867324e7d9664707b19a0c324a90bd06",
            "f134ecc715cf4982b05fd3f41ec8503c",
            "34144f54339a433494360369d721abdc",
            "bfa58ff1e4544863948337ba5c9fb6b7",
            "c9ca19978969410f950a11463fbfba6e",
            "3b947146cab54a79ad16e43d2105abbf",
            "2852527fc7e849a59c98f708dd95a0d5",
            "b5ff14f5713f4a89aa626308c748382e",
            "0d0eb941793c4a2898ea0c0ef8585c2c",
            "51dd2daca4f34ef4a2de3c11bd69c80c",
            "084f384a6ad348998fad597d5af6b1ea",
            "e0cae55975b241d7aeaf481d3a69a289",
            "61cb4bfb97f74e9ab33f293cb7b8c299",
            "2f0950d37c6545a5b4ff215eec41437a",
            "254e74c7f9664b638dfb5dcb94cec04d",
            "3d21321fe34e4fa690e5dca38d6239a8",
            "f83930319ed64f3e87d98d2a98e043a0",
            "a6897120679044089ba652224e8537e4",
            "9fec6010d5a040869d66883c2d7404ce",
            "7ce8c6d81c6b4d3cbd3b3cafcc3f2f39",
            "141c5f292a3d40a9acd777482ef6ff72",
            "0532aa8e18de468c91468c2522357037",
            "1997ada2a3e647f4b2069a038dc1a83a",
            "add0fd22aebe4c9f91828967dacc1cb3",
            "74d08d8dbab34063b9aebcd89dbbdfba",
            "b7ede8b152c14f138b16d62a7f8262c0",
            "982ee6f5be124ff7ae29d5cb5e434843",
            "37b884cf3f3247b3a0c6bb56a1f17187",
            "3fb2a2737af34512bee87732f8af91b9",
            "a518a4f60eb14680a41eae5d882e39c7",
            "f40d1fcbf6ce457fad59f4239f7237a3",
            "73910dbc7cdb4370a4532818d0361e09",
            "7842fb34e37744df9e234af36a10817b",
            "2f4c562a77ce48e9844ff04bd4367472",
            "051a2e567b244a5c85c73fbee7815565",
            "7524c7fb0f9d48bb8243f0885ca0d862",
            "97313da2a6614d61b6af5117b308e22e",
            "2770e5caf14e48b79ff445b4e060b9f7",
            "ffa2d900cf754733b7b53af1ea5f40ae",
            "05d32be1f79041b399c154986c5b2aa8",
            "7c1fef8d2ee0427bb2e30117875f918d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model initialized with norm initialization\n",
            "model initialized with norm initialization\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1cbd8a15c8d46b19592d304257b51fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fecffb9bd21a466e9d3adb78f4fa8cdd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e0b10e024b443da1c37f190fc07bb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d0eb941793c4a2898ea0c0ef8585c2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ce8c6d81c6b4d3cbd3b3cafcc3f2f39"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f40d1fcbf6ce457fad59f4239f7237a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-0c484d847c8c>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-0c484d847c8c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dl, epochs, display_every)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mupdate_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_meter_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# function updating the log objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-0fc6584d5d80>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-0fc6584d5d80>\u001b[0m in \u001b[0;36mbackward_D\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_D_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGANcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_D_fake\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_D_real\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def train_model(model, train_dl, epochs, display_every=200):\n",
        "    data = next(iter(val_dl)) # getting a batch for visualizing the model output after fixed intrvals\n",
        "    for e in range(epochs):\n",
        "        loss_meter_dict = create_loss_meters() # function returing a dictionary of objects to\n",
        "        i = 0                                  # log the losses of the complete network\n",
        "        for data in tqdm(train_dl):\n",
        "            model.setup_input(data)\n",
        "            model.optimize()\n",
        "            update_losses(model, loss_meter_dict, count=data['L'].size(0)) # function updating the log objects\n",
        "            i += 1\n",
        "            if i % display_every == 0:\n",
        "                print(f\"\\nEpoch {e+1}/{epochs}\")\n",
        "                print(f\"Iteration {i}/{len(train_dl)}\")\n",
        "                log_results(loss_meter_dict) # function to print out the losses\n",
        "                visualize(model, data, save=False) # function displaying the model's outputs\n",
        "\n",
        "model = MainModel()\n",
        "train_model(model, train_dl, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDfTKigHe2cA"
      },
      "source": [
        "Every epoch takes about 3 to 4 minutes on Colab. After about 20 epochs you should see some reasonable results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYTMpnZie2cA"
      },
      "source": [
        "Okay. I let the model train for some longer (about 100 epochs). Here are the results of our baseline model:\n",
        "\n",
        "![baseline](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/baseline.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTyc_Xuae2cB"
      },
      "source": [
        "As you can see, although this baseline model has some basic understanding of some most common objects in images like sky, trees, … its output is far from something appealing and it cannot decide on the color of rare objects. It also displays some color spillovers and circle-shaped mass of color (center of first image of second row) which is not good at all. So, it seems like that with this small dataset we cannot get good results with this strategy. **Therefore, we change our strategy!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tCOd5HWe2cB"
      },
      "source": [
        "## 2- A new strategy - the final model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynO4zBI8e2cB"
      },
      "source": [
        "Here is the focus of this article and where I'm going to explain what I did to overcome the last mentioned problem. Inspired by an idea in Super Resolution literature, I decided to pretrain the generator separately in a supervised and deterministic manner to avoid the problem of \"the blind leading the blind\" in the GAN game where neither generator nor discriminator knows anything about the task at the beginning of training.\n",
        "\n",
        "Actually I use pretraining in two stages: 1- The backbone of the generator (the down sampling path) is a pretrained model for classification (on ImageNet) 2- The whole generator will be pretrained on the task of colorization with L1 loss.\n",
        "\n",
        "In fact, I'm going to use a pretrained ResNet18 as the backbone of my U-Net and to accomplish the second stage of pretraining, we are going to train the U-Net on our training set with only L1 Loss. Then we will move to the combined adversarial and L1 loss, as we did in the previous section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMp5iDl3e2cB"
      },
      "source": [
        "### 2.1- Using a new generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxuDeu6Be2cC"
      },
      "source": [
        "Building a U-Net with a ResNet backbone is not something trivial so I'll use fastai library's Dynamic U-Net module to easily build one. You can simply install fastai with pip or conda (if you haven't already at the beginning of the tutorial). Here's the link to the [documentation](https://docs.fast.ai/).\n",
        "\n",
        "#### Update Jan 8th, 2022: <br>\n",
        "You need to install fastai version 2.4 for the following lines code to run w/o errors.\n",
        "If you have already installed it using the cell in the beginning of the tutorial, you don't need to install it here again.\n",
        "<br><br><br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL7hmRF1e2cC"
      },
      "outputs": [],
      "source": [
        "# pip install fastai==2.4\n",
        "from fastai.vision.learner import create_body\n",
        "from torchvision.models.resnet import resnet18\n",
        "from fastai.vision.models.unet import DynamicUnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvgQrAppe2cC"
      },
      "outputs": [],
      "source": [
        "def build_res_unet(n_input=1, n_output=2, size=256):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    body = create_body(resnet18, pretrained=True, n_in=n_input, cut=-2)\n",
        "    net_G = DynamicUnet(body, n_output, (size, size)).to(device)\n",
        "    return net_G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F07vF179e2cD"
      },
      "source": [
        "That's it! With just these few lines of code you can build such a complex model easily. create_body function loads the pretrained weights of the ResNet18 architecture and cuts the model to remove the last two layers (GlobalAveragePooling and a Linear layer for the ImageNet classification task). Then, DynamicUnet uses this backbone to build a U-Net with the needed output channels (2 in our case) and with an input size of 256."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77LanTXoe2cD"
      },
      "source": [
        "### 2.2 Pretraining the generator for colorization task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFMw1u0xe2cD"
      },
      "outputs": [],
      "source": [
        "def pretrain_generator(net_G, train_dl, opt, criterion, epochs):\n",
        "    for e in range(epochs):\n",
        "        loss_meter = AverageMeter()\n",
        "        for data in tqdm(train_dl):\n",
        "            L, ab = data['L'].to(device), data['ab'].to(device)\n",
        "            preds = net_G(L)\n",
        "            loss = criterion(preds, ab)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            loss_meter.update(loss.item(), L.size(0))\n",
        "\n",
        "        print(f\"Epoch {e + 1}/{epochs}\")\n",
        "        print(f\"L1 Loss: {loss_meter.avg:.5f}\")\n",
        "\n",
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "opt = optim.Adam(net_G.parameters(), lr=1e-4)\n",
        "criterion = nn.L1Loss()\n",
        "pretrain_generator(net_G, train_dl, opt, criterion, 20)\n",
        "#torch.save(net_G.state_dict(), \"res18-unet.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNRP2Mv-e2cE"
      },
      "source": [
        "With this simple function, we pretrain the generator for 20 epochs and then we save its weights. This will take an hour on Colab. In the following section, we will use this model as the generator for our GAN and train the whole network as before:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnbqHR4De2cE"
      },
      "source": [
        "### 2.3 Putting everything together, again!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FDleoQze2cE"
      },
      "source": [
        "If you want to train the model yourself, run the following cell. Instead, if you want to use the pretrained weights, skip the cell and run the one after that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEwocD0Ye2cF"
      },
      "outputs": [],
      "source": [
        "net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n",
        "model = MainModel(net_G=net_G)\n",
        "train_model(model, train_dl, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25zhWREde2cF"
      },
      "source": [
        "Here I'm first loading the saved weights for the generator (which you have saved in the previous section) and then I'm using this model as the generator in our MainModel class  which prevents it from randomly initializing the generator. Then we train the model for 10 to 20 epochs! (compare it to the 100 epochs of the previous section when we didn't use pretraining). Each epoch takes about 3 to 4 minutes on Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lta-IOLle2cF"
      },
      "source": [
        "If you are on Colab and want to use the pretrained weights, run the following cells which download the weights from my google drive and loads it to the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5IwOl0ge2cG"
      },
      "outputs": [],
      "source": [
        "# !gdown --id 1lR6DcS4m5InSbZ5y59zkH2mHt_4RQ2KV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4T07jfDe2cG"
      },
      "outputs": [],
      "source": [
        "# net_G = build_res_unet(n_input=1, n_output=2, size=256)\n",
        "# net_G.load_state_dict(torch.load(\"res18-unet.pt\", map_location=device))\n",
        "# model = MainModel(net_G=net_G)\n",
        "# model.load_state_dict(torch.load(\"final_model_weights.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61n424USe2cG"
      },
      "source": [
        "Now, I will show the results of this final model on the test set (the black and white images that it has never seen during training) including the main title image of this article at the very beginning:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv7XfSUqe2cH"
      },
      "source": [
        "![output 1](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/main.png?raw=1)\n",
        "Left: Input black & white images from test set | Right: the colorized outputs by the final model of this tutorial\n",
        "---\n",
        "![output2](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/img1.png?raw=1)\n",
        "Left: Input black & white images from test set | Right: the colorized outputs by the final model of this tutorial\n",
        "---\n",
        "![output3](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/img2.png?raw=1)\n",
        "Left: Input black & white images from test set | Right: the colorized outputs by the final model of this tutorial\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es13d-j0e2cH"
      },
      "source": [
        "## An accidental finding: You can safely remove Dropout!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kAwiNM5e2cH"
      },
      "source": [
        "Remember that when I was explaining the theory of conditional GAN in the beginning of this article, I said that the source of the noise in the architecture of the generator proposed by authors of the paper was the dropout layers. However, when I investigated the U-Net we built with the help of fastai, I did not find any dropout layers in there! Actually I first trained the final model and got the results and then I investigated the generator and found this out.\n",
        "\n",
        "So, was the adversarial training useless? If there is no noise, how possibly the generator can have a creative effect on the output? Is it possible that the input grayscale image to the generator plays the role of noise as well? These were my exact questions at the time.\n",
        "\n",
        "Therefor, I decided to email Dr. Phillip Isola, the first author of the same paper we implemented here, and he kindly answered these questions. According to what he said,  this conditional GAN can still work without dropout but the outputs will be more deterministic because of the lack of that noise; however, there is still enough information in that input grayscale image which enables the generator to produce compelling outputs.\n",
        "Actually, I saw this in practice that the adversarial training was helpful indeed. In the next and last section, I'm going to compare the results of the pretrained U-Net with no adversarial training against the final outputs we got with adversarial training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0cGdGI0e2cH"
      },
      "source": [
        "## Comparing the results of the pretrained U-Net with and without adversarial training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of8sIgDVe2cH"
      },
      "source": [
        "One of the cool thing I found in my experiments was that the U-Net we built with the ResNet18 backbone is already awesome in colorizing images after pretraining with L1 Loss only (a step before the final adversarial training). But, the model is still conservative and encourages using gray-ish colors when it is not sure about what the object is or what color it should be. However, it performs really awesome for common scenes in the images like sky, tree, grass, etc.\n",
        "\n",
        "Here I show you the outputs of the U-Net without adversarial training and U-Net with adversarial training to better depict the significant difference that the adversarial training is making in our case:\n",
        "\n",
        "![comparison](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/comparison1.png?raw=1)\n",
        "(Left: pretrained U-Net without adversarial training | Right: pretrained U-Net with adversarial training)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPLOLV_0e2cI"
      },
      "source": [
        "You can also see the GIF below to observe the difference between the images better:\n",
        "\n",
        "![anim](https://github.com/moein-shariatnia/Deep-Learning/blob/main/Image%20Colorization%20Tutorial/files/anim_compare.gif?raw=1)\n",
        "(animation of the last two images to better see the significant difference that adversarial training is making)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdcbCu1re2cJ"
      },
      "source": [
        "## Final words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE3K3y1Ie2cJ"
      },
      "source": [
        "This project was full of important lessons for myself. I spent a lot of time during the last month to implement lots of different papers each with different strategies and it took quite a while and after A LOT of failures that I could come up with this method of training. Now you can see that how pretraining the generator significantly helped the model and improved the results.\n",
        "\n",
        "I also learned that some observations, although at first feeling like a bad mistake of yours, are worth paying attention to and further investigation; like the case of dropout in this project. Thanks to the helpful community of deep learning and AI, you can easily ask experts and get the answer you need and become more confidant in what you were just guessing.\n",
        "\n",
        "I want to thank the authors of this wonderful paper for their awesome work and also [the great GitHub repository of this paper](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) from which I borrowed some of the codes (with modification and simplification). I truly love the community of computer science and AI and all their hard work to improve the field and also make their contributions available to all. I'm happy to be a tiny part of this community."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1cbd8a15c8d46b19592d304257b51fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1226adf58bc648a092a2d738aae6bd54",
              "IPY_MODEL_d78a8ac934da426287a78f74bf62a356",
              "IPY_MODEL_7b6123098bb447c689a1f8ba9c9c59c9"
            ],
            "layout": "IPY_MODEL_7c268f2e49ac4cbe9b303cdbaab10b65"
          }
        },
        "1226adf58bc648a092a2d738aae6bd54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99a235ff24cf45f598fa848e27a752c1",
            "placeholder": "​",
            "style": "IPY_MODEL_437a0b8864f348cb878e4057134dfe2f",
            "value": "100%"
          }
        },
        "d78a8ac934da426287a78f74bf62a356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca688562fc134ac8820addb3992c6275",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e735fb91fff46e7bad1cdfbc3c04250",
            "value": 5
          }
        },
        "7b6123098bb447c689a1f8ba9c9c59c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2340cb03c4ed4062b0ffbe79467d90d3",
            "placeholder": "​",
            "style": "IPY_MODEL_e1bfdd07017b4cec9f6271fc52ebae38",
            "value": " 5/5 [03:15&lt;00:00, 37.75s/it]"
          }
        },
        "7c268f2e49ac4cbe9b303cdbaab10b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a235ff24cf45f598fa848e27a752c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437a0b8864f348cb878e4057134dfe2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca688562fc134ac8820addb3992c6275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e735fb91fff46e7bad1cdfbc3c04250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2340cb03c4ed4062b0ffbe79467d90d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1bfdd07017b4cec9f6271fc52ebae38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fecffb9bd21a466e9d3adb78f4fa8cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51de08c352d24568975f4eb088a5e377",
              "IPY_MODEL_1d07e546e5f94b36a1da5aeaae4e5fef",
              "IPY_MODEL_5f6b42ef5e474117b1c66e21d03bc1e0"
            ],
            "layout": "IPY_MODEL_19bd16d82c8f4930a2fbd5e44599f7fb"
          }
        },
        "51de08c352d24568975f4eb088a5e377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b62e272bb4f44ed5adc93a3896da823e",
            "placeholder": "​",
            "style": "IPY_MODEL_88c5332ace35437a946074f9fa867652",
            "value": "100%"
          }
        },
        "1d07e546e5f94b36a1da5aeaae4e5fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cf9bcaa80244c02825aea36ca56902e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bad6f640cbaf46bd80a152d787fc2adb",
            "value": 5
          }
        },
        "5f6b42ef5e474117b1c66e21d03bc1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d33a494d1dc04369ab4ed235049d13ea",
            "placeholder": "​",
            "style": "IPY_MODEL_e1b666e08e824f79b4c21336fc0bbbe5",
            "value": " 5/5 [03:01&lt;00:00, 35.94s/it]"
          }
        },
        "19bd16d82c8f4930a2fbd5e44599f7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b62e272bb4f44ed5adc93a3896da823e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c5332ace35437a946074f9fa867652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cf9bcaa80244c02825aea36ca56902e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad6f640cbaf46bd80a152d787fc2adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d33a494d1dc04369ab4ed235049d13ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b666e08e824f79b4c21336fc0bbbe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e0b10e024b443da1c37f190fc07bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4947df8fd7b44d186003b8dd426f2b9",
              "IPY_MODEL_f2a224e39c21442fa619191e27daa45b",
              "IPY_MODEL_867324e7d9664707b19a0c324a90bd06"
            ],
            "layout": "IPY_MODEL_f134ecc715cf4982b05fd3f41ec8503c"
          }
        },
        "c4947df8fd7b44d186003b8dd426f2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34144f54339a433494360369d721abdc",
            "placeholder": "​",
            "style": "IPY_MODEL_bfa58ff1e4544863948337ba5c9fb6b7",
            "value": "100%"
          }
        },
        "f2a224e39c21442fa619191e27daa45b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ca19978969410f950a11463fbfba6e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b947146cab54a79ad16e43d2105abbf",
            "value": 5
          }
        },
        "867324e7d9664707b19a0c324a90bd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2852527fc7e849a59c98f708dd95a0d5",
            "placeholder": "​",
            "style": "IPY_MODEL_b5ff14f5713f4a89aa626308c748382e",
            "value": " 5/5 [03:07&lt;00:00, 36.63s/it]"
          }
        },
        "f134ecc715cf4982b05fd3f41ec8503c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34144f54339a433494360369d721abdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa58ff1e4544863948337ba5c9fb6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ca19978969410f950a11463fbfba6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b947146cab54a79ad16e43d2105abbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2852527fc7e849a59c98f708dd95a0d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ff14f5713f4a89aa626308c748382e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d0eb941793c4a2898ea0c0ef8585c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51dd2daca4f34ef4a2de3c11bd69c80c",
              "IPY_MODEL_084f384a6ad348998fad597d5af6b1ea",
              "IPY_MODEL_e0cae55975b241d7aeaf481d3a69a289"
            ],
            "layout": "IPY_MODEL_61cb4bfb97f74e9ab33f293cb7b8c299"
          }
        },
        "51dd2daca4f34ef4a2de3c11bd69c80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f0950d37c6545a5b4ff215eec41437a",
            "placeholder": "​",
            "style": "IPY_MODEL_254e74c7f9664b638dfb5dcb94cec04d",
            "value": "100%"
          }
        },
        "084f384a6ad348998fad597d5af6b1ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d21321fe34e4fa690e5dca38d6239a8",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f83930319ed64f3e87d98d2a98e043a0",
            "value": 5
          }
        },
        "e0cae55975b241d7aeaf481d3a69a289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6897120679044089ba652224e8537e4",
            "placeholder": "​",
            "style": "IPY_MODEL_9fec6010d5a040869d66883c2d7404ce",
            "value": " 5/5 [03:00&lt;00:00, 35.76s/it]"
          }
        },
        "61cb4bfb97f74e9ab33f293cb7b8c299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f0950d37c6545a5b4ff215eec41437a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "254e74c7f9664b638dfb5dcb94cec04d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d21321fe34e4fa690e5dca38d6239a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83930319ed64f3e87d98d2a98e043a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6897120679044089ba652224e8537e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fec6010d5a040869d66883c2d7404ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ce8c6d81c6b4d3cbd3b3cafcc3f2f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_141c5f292a3d40a9acd777482ef6ff72",
              "IPY_MODEL_0532aa8e18de468c91468c2522357037",
              "IPY_MODEL_1997ada2a3e647f4b2069a038dc1a83a"
            ],
            "layout": "IPY_MODEL_add0fd22aebe4c9f91828967dacc1cb3"
          }
        },
        "141c5f292a3d40a9acd777482ef6ff72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d08d8dbab34063b9aebcd89dbbdfba",
            "placeholder": "​",
            "style": "IPY_MODEL_b7ede8b152c14f138b16d62a7f8262c0",
            "value": "100%"
          }
        },
        "0532aa8e18de468c91468c2522357037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982ee6f5be124ff7ae29d5cb5e434843",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37b884cf3f3247b3a0c6bb56a1f17187",
            "value": 5
          }
        },
        "1997ada2a3e647f4b2069a038dc1a83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb2a2737af34512bee87732f8af91b9",
            "placeholder": "​",
            "style": "IPY_MODEL_a518a4f60eb14680a41eae5d882e39c7",
            "value": " 5/5 [02:58&lt;00:00, 34.94s/it]"
          }
        },
        "add0fd22aebe4c9f91828967dacc1cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d08d8dbab34063b9aebcd89dbbdfba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7ede8b152c14f138b16d62a7f8262c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "982ee6f5be124ff7ae29d5cb5e434843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b884cf3f3247b3a0c6bb56a1f17187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fb2a2737af34512bee87732f8af91b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a518a4f60eb14680a41eae5d882e39c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f40d1fcbf6ce457fad59f4239f7237a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73910dbc7cdb4370a4532818d0361e09",
              "IPY_MODEL_7842fb34e37744df9e234af36a10817b",
              "IPY_MODEL_2f4c562a77ce48e9844ff04bd4367472"
            ],
            "layout": "IPY_MODEL_051a2e567b244a5c85c73fbee7815565"
          }
        },
        "73910dbc7cdb4370a4532818d0361e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7524c7fb0f9d48bb8243f0885ca0d862",
            "placeholder": "​",
            "style": "IPY_MODEL_97313da2a6614d61b6af5117b308e22e",
            "value": " 60%"
          }
        },
        "7842fb34e37744df9e234af36a10817b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2770e5caf14e48b79ff445b4e060b9f7",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffa2d900cf754733b7b53af1ea5f40ae",
            "value": 3
          }
        },
        "2f4c562a77ce48e9844ff04bd4367472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05d32be1f79041b399c154986c5b2aa8",
            "placeholder": "​",
            "style": "IPY_MODEL_7c1fef8d2ee0427bb2e30117875f918d",
            "value": " 3/5 [02:07&lt;01:11, 35.61s/it]"
          }
        },
        "051a2e567b244a5c85c73fbee7815565": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7524c7fb0f9d48bb8243f0885ca0d862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97313da2a6614d61b6af5117b308e22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2770e5caf14e48b79ff445b4e060b9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa2d900cf754733b7b53af1ea5f40ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05d32be1f79041b399c154986c5b2aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c1fef8d2ee0427bb2e30117875f918d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}